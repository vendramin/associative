\chapter{}

\topic{Herstein's theorem}

Our aim now is to answer the following question: When
a group algebra is algebraic? 
A partial answer is given by Herstein's theorem. 

\begin{definition}
\index{Group!locally finite}
	A group $G$ is \textbf{locally finite} if every finitely generated 
	subgroup of $G$ is finite. 
\end{definition}

If $G$ is a locally finite group, then every element $g\in G$ has finite order, as
the subgroup $\langle g\rangle$ is finite because it is finitely generated.

\begin{example}
    Every finite group is locally finite
\end{example}

\begin{example}
    The group $\Z$ is not locally finite because it is torsion-free.
\end{example}

\begin{example}
\index{Pr\"ufer's group}
	Let $p$ be a prime number. 
	The \textbf{Pr\"ufer's group}  
	\[
		\Z(p^{\infty})=\{z\in\C:z^{p^n}=1\text{ para algún $n\in\Z_{>0}$}\}, 
	\]
	formed by of all $p$-roots of one, is locally finite. 
\end{example}

\begin{example}
	Let $X$ be an infinite set and $\Sym_X$ be the set of bijective maps $X\to
	X$ moving only finitely many elements of $X$. Then 
	$\Sym_X$ is locally finite.
\end{example}

\begin{proposition}
\label{pro:exact_LI}
	Let $G$ be a group and $N$ be a normal subgroup of $G$. If $N$ and $G/N$
	are locally finite, then $G$ is locally finite.
\end{proposition}

\begin{proof}
	Let $\pi\colon G\to G/N$ be the canonical map and $\{g_1,\dots,g_n\}$ be a finite subset of $G$. 
	Since $G/N$ is locally finite, the subgroup $Q$ of $G/N$ generated by 
	$\pi(g_1),\dots,\pi(g_n)$ is finite, say
	\[
		Q=\{\pi(g_1),\dots,\pi(g_n),\pi(g_{n+1}),\dots,\pi(g_m)\}.
	\]
	For each $i,j\in\{1,\dots,n\}$ there exist $u_{ij}\in N$ and 
	$k\in\{1,\dots,m\}$ uch that $g_ig_j=u_{ij}g_k$. Let $U$ be the subgroup of $G$
	generated by $\{u_{ij}:1\leq i,j\leq n\}$. Since $N$ is locally finite, $U$ is finite. Moreover, since 
	each $g_ig_jg_l$ can be written as 
	\[
		g_ig_jg_l=u_{ij}g_kg_l=u_{ij}u_{kl}g_t=ug_t
	\]
	for some $u\in U$ and $t\in\{1,\dots,m\}$, it follows that the subgroup 
	$H$ of $G$ generated by $\{g_1,\dots,g_n\}$ is finite, as 
	$|H|\leq m|U|$. 
\end{proof}

\index{Group!solvable}
Recall that a group $G$ is
\textbf{solvable} if there exists a sequence
of subgroups 
\begin{equation}
	\label{eq:resoluble}
	\{1\}=G_0\subsetneq G_1\subsetneq \cdots\subsetneq G_n=G
\end{equation}
where each $G_i$ is normal in $G_{i+1}$ and each 
quotient $G_i/G_{i-1}$ is
abelian.
\index{Group!torsion}
A group $G$ is a \textbf{torsion} group if every element of $G$
has finite order. 

\begin{proposition}
	If $G$ is a solvable torsion group, 
	then $G$ is locally finite. 
\end{proposition}

\begin{proof}
	We proceed by induction on $n$, the length of the sequence~\eqref{eq:resoluble}. 
	If $n=1$, then $G$ is finite because it is abelian and a torsion group.
	Now assume the result holds for group with resolubility length $n-1$ and let
	$G$ be a solvable group with a sequence~\eqref{eq:resoluble}. By the inductive hypothesis, 
	the normal subgroup $G_{n-1}$ of $G$ is locally finite. Since $G/G_{n-1}$ is an abelian torsion group, 
	it is locally finite, the result now follows from Proposition \ref{pro:exact_LI}.
\end{proof}

We now prove Herstein's theorem.

\begin{theorem}[Herstein]
\index{Herstein's theorem}
	If $G$ is a locally finite group, then $K[G]$ is algebraic. Conversely, if 
	$K[G]$ is algebraic and $K$ has characteristic zero, then $G$ 
	is locally finite. 
\end{theorem}

\begin{proof}
	Assume thast $G$ is locally finite. Let $\alpha\in K[G]$. The subgroup 
	$H=\langle\supp\alpha\rangle$ is finite, as it is finitely generated. Since 
	$\alpha\in K[H]$ and $\dim_KK[H]<\infty$, the set 
	$\{1,\alpha,\alpha^2,\dots\}$ is linearly dependent. Thus $\alpha$ is
	algebraic over $K$.

	Let $\{x_1,\dots,x_m\}$ be a finite subset of $G$. Adding inverses if needed,
	we may assume that $\{x_1,\dots,x_m\}$ generates the subgroup 
	$H=\langle x_1,\dots,x_m\rangle$ as a semigroup. If
	$\alpha=x_1+\dots+x_m\in K[G]$, then, since $\alpha$ is algebraic over $K$, 
	\[
		\alpha^{n+1}=a_0+a_1\alpha+\cdots+a_n\alpha^n
	\]
	for some $n\geq0$ and $a_0,\dots,x_n\in K$. Let $w=x_{i_1}\cdots
	x_{i_{n+1}}\in H$ be a word of length $n+1$. There exist positive integers 
	$c_{i_1\cdots i_m}$ such that 
	\[
		\alpha^{n+1}=(x_1+\cdots+x_m)^{n+1}
		=\sum_{\substack{{i_1+\cdots+i_m=n+1}\\{\text{$i_j$ positive integers}}}} c_{i_1\cdots i_m}x_1^{i_1}\cdots x_{m}^{i_m}.
	\]
	Since $K$
	is of characteristic zero, it follows that $w\in\supp(\alpha^{n+1})$. Since, moreover,  
	$\alpha^{n+1}=\sum_{j=0}^na_j\alpha^j$, it follows that 
	$w\in\supp(\alpha^j)$ for some $j\in\{0,\dots,n\}$. Thus each
	word in the letters $x_j$ of length $n+1$ can be written as a word in the letters $x_j$ of 
	length $\leq n$. Therefore $H$ is finite and hence $G$ is locally finite. 
\end{proof}


\topic{Formanek's theorem, I}

\begin{exercise}
\label{xca:invertible_algebraic}
	Let $A$ be an algebraic algebra and $a\in A$.
	\begin{enumerate}
		\item $a$ is a left zero divisor if and only if $a$ is a right zero divisor.
		\item $a$ is left invertible if and only if $a$ is right invertible.
		\item $a$ is invertible if and only if $a$ is not a zero divisor.
	\end{enumerate}
\end{exercise}

\begin{exercise}
	\label{exa:norma}
	For $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$ let $|\alpha|=\sum_{g\in
	G}|\alpha_g|\in\R$. Prove the following statements:
	\begin{enumerate}
		%\item $|\trace(\alpha)|\leq |\alpha|$, 
		\item $|\alpha+\beta|\leq|\alpha|+|\beta|$, and 
		\item $|\alpha\beta|\leq|\alpha||\beta|$ 
	\end{enumerate}
	for all $\alpha,\beta\in\C[G]$.
\end{exercise}

\begin{theorem}[Formanek]
	\label{thm:FormanekQ}
	\index{Formanek's theorem}
	Let $G$ be a group. If every element of $\Q[G]$ is invertible or 
	a zero divisor, then $G$ is locally finite. 
\end{theorem}

\begin{proof}
	Let $\{x_1,\dots,x_n\}$ be a finite subset of $G$. Adding inverses if needed, we may assume that 
	$\{x_1,\dots,x_n\}$ generates the subgroup
	$H=\langle x_1,\dots,x_n\rangle$ as a semigroup. Let 
	\[
		\alpha=\frac{1}{2n}(x_1+\cdots+x_n)\in\Q[G]
	\]

	We claim that $1-\alpha\in\Q[G]$ is invertible. If not, then it is a zero divisor. If there exists 
	$\delta\in\Q[G]$ such that $\delta(1-\alpha)=0$, then 
	$\delta=\delta\alpha$. Since  
	\[
		|\delta|=|\delta\alpha|\leq|\delta||\alpha|=|\delta|/2,
	\]
	it follows that $\delta=0$. Similarly, $(1-\alpha)\delta=0$ implies
	$\delta=0$. 
	
	Let $\beta=(1-\alpha)^{-1}\in\Q[G]$.  For each$k$ let  
	\[
		\gamma_k=(1+\alpha+\cdots+\alpha^k)-\beta.
	\]
	Then 
	\begin{align*}
		\gamma_k(1-\alpha)&=(1+\alpha+\cdots+\alpha^k-\beta)(1-\alpha)\\
		&=(1+\alpha+\cdots+\alpha^k)(1-\alpha)-\beta(1-\alpha)=-\alpha^{k+1}
	\end{align*}
	and thus  
	$\gamma_k=-\alpha^{k+1}\beta$. Since  
	\[
		|\gamma_k|=|-\alpha^{k+1}\beta|\leq|\beta||\alpha^{k+1}|=\frac{|\beta|}{2^{k+1}},
	\]
	it follows that $\lim_{k\to\infty}|\gamma_k|=0$. 

	We now prove that $H\subseteq\supp\beta$. If
	$H\not\subseteq\supp\beta$, let $h\in H\setminus\supp\beta$.  Assume that 
    $h=x_{i_1}\cdots x_{i_m}$ is a word in the letters $x_j$ of length $m$. Let 
    $c_j$ be the coefficient of $h$ in $\alpha^j$. Then $c_0+\cdots+c_k$ is the 
	coefficient of $h$ in $\gamma_k$, but 
	\[
		|\gamma_k|\geq c_0+c_1+\cdots+c_k\geq c_m>0
	\]
	for all $k\geq m$, as each $c_j$ is non-negative, a contradiction to 
	$|\gamma_k|\to 0$ si $k\to\infty$.
\end{proof}

\topic{Formanek's theorem, II}

The \textbf{tensor product} of the vector spaces (over $K$) $U$ and $V$ 
is the quotient vector space $K[U\times V]/T$, where $K[U\times V]$ 
is the vector space with basis 
\[
\{(u,v):u\in U,v\in V\}
\]
and $T$ is the subspace 
generated by elements of the form 
\[
		(\lambda u+\mu u',v)-\lambda(u,v)-\mu(u',v),\quad
		(u,\lambda v+\mu v')-\lambda(u,v)-\mu(u,v')
	\]
for $\lambda,\mu\in K$, $u,u'\in U$ and $v,v'\in V$.
The tensor product of $U$ and $V$ will be denoted by $U\otimes_KV$ or 
$U\otimes V$ when the base field it is clear from the context. For $u\in U$ and 
$v\in V$ we write $u\otimes v$ to denote the coset $(u,v)+T$.

\begin{theorem}
	Let $U$ and $V$ be vector spaces. Then there exists a bilinear map 
	$U\times V\to U\otimes V$, $(u,v)\mapsto u\otimes v$, such that 
	each element of $U\otimes V$ is a finite sum of the form 
	\[
		\sum_{i=1}^N u_i\otimes v_i
	\]
	for some $u_1,\dots,u_N\in U$ and $v_1,\dots,v_N\in V$. 
	Moreover, if $W$ is a vector space and $\beta\colon U\times V\to W$ is a bilinear map, 
	there exists a linear map 
	$\overline{\beta}\colon U\otimes V\to W$ such that $\overline{\beta}(u\otimes
	v)=\beta(u,v)$ for all $u\in U$ and $v\in V$.
\end{theorem}

\begin{proof}
    By definition, the map
    \[
	U\times V\to U\otimes V,\quad
	(u,v)\mapsto u\otimes v,
	\]
	is bilinear. From the definitions it follows that
	$U\otimes V$ is a finite linear combination of elements of the form 
	$u\otimes v$, where $u\in U$ and $v\in V$. Since $\lambda(u\otimes
	v)=(\lambda u)\otimes v$ for all $\lambda\in K$, the first claim follows.

	Since the elements of $U\times V$ form a basis of $K[U\times V]$, there exists
	a linear map 
	\[
		\gamma\colon K[U\times V]\to W,\quad
	\gamma(u,v)=\beta(u,v). 
	\]
	Since $\beta$ is bilinear by assumption, $T\subseteq\ker\gamma$. It follows that there exists 
	a linear map $\overline{\beta}\colon U\otimes V\to
	W$ such that  
	\[
	\begin{tikzcd}
		K[U\times V] \arrow[r]\arrow[d] & W \\
		U\otimes V\arrow[ur, dashrightarrow]
	\end{tikzcd}
	\]
	commutes. In particular, $\overline{\beta}(u\otimes v)=\beta(u,v)$. 
\end{proof}

\begin{exercise}
	\label{xca:tensorial_unicidad}
	Prove that the properties of the previous theorem characterize tensor products up to isomorphism. 
\end{exercise}

Some properties:
%Observemos
%que todo elemento de $U\otimes V$ es una suma finita
%de la forma 
%\[
%	\sum_{i=1}^N u_i\otimes v_i
%\]
%para $N\in\N$, $u_i\in U$ y $v_i\in V$. Esta expresión no es única. Vale además
%que $u\otimes 0=0=0\otimes v$ para todo $u\in U$ y $v\in V$.

\begin{proposition}
	Let $\varphi\colon U\to U_1$ and $\psi\colon V\to V_1$ be linear maps. There
	exists a unique linear map 
	$\varphi\otimes\psi\colon U\otimes V\to U_1\otimes V_1$ such that
	\[
		(\varphi\otimes\psi)(u\otimes v)=\varphi(u)\otimes\psi(v)
	\]
	for all $u\in U$ and $v\in V$.
\end{proposition}

\begin{proof}
	Since $U\times V\to U_1\otimes V_1$,
	$(u,v)\mapsto\varphi(u)\otimes\psi(v)$, is bilinear, there exists a linear map
	$U\otimes V\to U_1\otimes V_1$, $u\otimes
	v\to\varphi(u)\otimes\psi(v)$. Thus 
	\[
		\sum u_i\otimes v_i\mapsto\sum\varphi(u_i)\otimes\psi(v_i)
	\]
	is well-defined. 
\end{proof}

\begin{exercise}
    Prove the following statements:
	\begin{enumerate}
		\item $(\varphi\otimes\psi)(\varphi'\otimes\psi')=(\varphi\varphi')\otimes(\psi\psi')$.
		\item If $\varphi$ and $\psi$ are isomorphisms, then 
			$\varphi\otimes\psi$ is an isomorphism. 
		\item $(\lambda\varphi+\lambda'\varphi')\otimes\psi=\lambda\varphi\otimes\psi+\lambda'\varphi'\otimes\psi$.
		\item $\varphi\otimes(\lambda\psi+\lambda'\psi')=\lambda\varphi\otimes\psi+\lambda'\varphi\otimes\psi'$.
		\item If $U\simeq U_1$ and $V\simeq V_1$, then $U\otimes V\simeq U_1\otimes V_1$.
	\end{enumerate}
\end{exercise}

The following proposition is extremely useful:

\begin{proposition}
	If $U$ and $V$ are vector spaces, then  
	$U\otimes V\simeq V\otimes U$.
\end{proposition}

\begin{proof}
	Since $U\times V\to V\otimes U$, $(u,v)\mapsto v\otimes u$, is bilinear, there exists 
	a linear map $U\otimes V\to V\otimes U$, $u\otimes
	v\mapsto v\otimes u$. Similarly, there exists a linear map 
	$V\otimes U\to U\otimes V$, $v\otimes u\mapsto
	u\otimes v$. Thus $U\otimes V\simeq V\otimes U$.
\end{proof}

\begin{exercise}
	\label{xca:UxVxW}
    Prove that $(U\otimes V)\otimes W\simeq U\otimes(V\otimes W)$.
\end{exercise}

\begin{exercise}
	\label{xca:UxK}
	Prove that $U\otimes K\simeq K\simeq K\otimes U$.
\end{exercise}

\begin{proposition}
	\label{pro:U_LI}
	Let $U$ and $V$ be vector spaces. 
	If $\{u_1,\dots,u_n\}$ is a linearly independent subset of $U$ and 
	$v_1,\dots,v_n\in V$ is such that $\sum_{i=1}^n u_i\otimes v_i=0$, then 
    $v_i=0$ for all $i\in\{1,\dots,n\}$.
\end{proposition}

\begin{proof}
	Let $i\in\{1,\dots,n\}$ and 
	\[
	f_i\colon U\to K,
	\quad
	f_i(u_j)=\delta_{ij}=\begin{cases}
	1 & \text{if $i=j$},\\
	0 & \text{otherwise}.
	\end{cases}
	\]
	Since the map $U\times V\to V$, $(u,v)\mapsto f_i(u)v$, is bilinear, there exists 
	a linear map 
	$\alpha_i\colon U\otimes V\to V$ such that $\alpha_i(u\otimes
	v)=f_i(u)v$. Thus
	\[
		v_i=\sum_{j=1}^n\alpha_i(u_j\otimes v_j)=\alpha_i\left(\sum_{j=1}^nu_j\otimes v_j\right)=0.\qedhere
	\]
\end{proof}

\begin{exercise}
	\label{xca:uxv=0}
	Prove that $u\otimes v=0$ and $v\ne 0$ imply $u=0$.
\end{exercise}

\begin{theorem}
    Let $U$ and $V$ be vector spaces. 
	If $\{u_i:i\in I\}$ is a basis of $U$ and $\{v_j:j\in J\}$ is a basis of $V$, then 
	$\{u_i\otimes v_j:i\in I,j\in J\}$ is a basis of $U\otimes
	V$.
\end{theorem}

\begin{proof}
	The $u_i\otimes v_j$ are generators of $U\otimes V$, as  
    $u=\sum_i\lambda_iu_i$ and $v=\sum_j\mu_jv_j$ imply 
	$u\otimes v=\sum_{i,j}\lambda_i\mu_ju_i\otimes v_j$. 
	We now prove that the $u_i\otimes v_j$ are linearly independent. We need to show that
	each finite subset of the $u_i\otimes v_j$
	is linearly independent. If $\sum_k\sum_l\lambda_{kl}u_{i_k}\otimes
	v_{j_l}=0$, then 
	$0=\sum_{k}u_{i_k}\otimes\left(\sum_{l}\lambda_{kl}v_{j_l}\right)$. Since  
	the $u_{i_k}$ are linearly independent, Proposition~\ref{pro:U_LI}
	implies that $\sum_{l}\lambda_{kl}v_{j_l}=0$. Thus $\lambda_{kl}=0$ for all 
	$k,l$, as the $v_{j_l}$ are linearly independent. 
\end{proof}

If $U$ and $V$ are finite-dimensional vector spaces, then 
\[
	\dim(U\otimes V)=(\dim U)(\dim V).
\]

\begin{corollary}
	If $\{u_i:i\in I\}$ is basis of $U$, then every element of $U\otimes V$
	can be written uniquely as a finite sum $\sum_{i}u_i\otimes v_i$.
\end{corollary}

\begin{proof}
	Every element of $U\otimes V$ is a finite sum 
	$\sum_i x_i\otimes y_i$, where $x_i\in U$ and $y_i\in V$. If  
	$x_i=\sum_j\lambda_{ij}u_j$, then 
	\[
		\sum_i x_i\otimes y_i=\sum_i\left(\sum_j\lambda_{ij}u_j\right)\otimes y_i		
		=\sum_j u_j\otimes\left(\sum_i\lambda_{ij}y_i\right).\qedhere 
	\]
\end{proof}

%\begin{corollary}
%	Todo elemento no nulo de $U\otimes V$ puede escribirse como una suma finita
%	$\sum_{i=1}^N u_i\otimes v_i$ para un conjuntos $\{u_i:1\leq i\leq
%	N\}\subseteq U$ y $\{v_i:1\leq i\leq N\}\subseteq V$ linealmente
%	independientes.
%\end{corollary}
%
%\begin{proof}
%	tomar $N$ minimal	
%\end{proof}

\begin{exercise}
\label{xca:tensor_algebras}
    Let $A$ and $B$ be algebras. Prove that $A\otimes B$ 
    is an algebra with 
	\[
		(a\otimes b)(x\otimes y)=ax\otimes by.
	\]
\end{exercise}

% \begin{proof}
% 	Para $x\in A$, $y\in B$ consideramos $R_x\otimes R_y\in\End_K(A\otimes B)$.
% 	Como la función $A\times B\to\End_K(A\otimes B)$, $(x,y)\mapsto R_x\otimes
% 	R_y$, es bilineal, existe una función lineal $\varphi\colon A\otimes
% 	B\to\End_K(A\otimes B)$, $\varphi(x\otimes y)=R_x\otimes R_y$. Para $u,v\in A\otimes B$ definimos
% 	\[
% 		uv=\varphi(v)(u).
% 	\]
% 	Esta operación es bilineal pues por ejemplo
% 	\[
% 		u(v+w)=\varphi(v+w)(u)=(\varphi(v)+\varphi(w))(u)=\varphi(v)(u)+\varphi(w)(u)=uv+uw.
% 	\]
% 	Además
% 	$(a\otimes b)(x\otimes y)=\varphi(x\otimes y)(a\otimes b)=(R_x\otimes R_y)(a\otimes b)=ax\otimes by$.
% 	Un cálculo sencillo muestra que este producto es asociativo.
% \end{proof}

\begin{exercise}
    Prove the following statements:
	\begin{enumerate}
		\item $A\otimes B\simeq B\otimes A$.
		\item $(A\otimes B)\otimes C\simeq A\otimes(B\otimes C)$.
		\item $A\otimes K\simeq A\simeq K\otimes A$.
		\item If $A\otimes A_1$ and $B\otimes B_1$, then $A\otimes B\simeq A_1\otimes B_1$.
	\end{enumerate}
\end{exercise}

Some examples:

\begin{proposition}
	If $G$ and $H$ are groups, then $K[G]\otimes K[H]\simeq K[G\times H]$.
\end{proposition}

\begin{proof}
	The set $\{g\otimes h:g\in G,h\in H\}$ is a basis of $K[G]\otimes K[H]$ and 
	the elements of $G\times H$ form a basis of $K[G\times H]$. There exists a linear isomorphism 
	\[
	K[G]\otimes K[H]\to K[G\times H], 
	\quad 
	g\otimes h\mapsto (g,h),
	\]
	that is multiplicative. Thus $K[G]\otimes K[H]\simeq K[G\times H]$
	as algebras. 
\end{proof}

\begin{proposition}
\label{pro:AKX=AX}
	If $A$ is an algebra, then $A\otimes K[X]\simeq A[X]$.	
\end{proposition}

\begin{proof}
	Each element of $A\otimes K[X]$ can be written uniquely as a finite sum of
	the form $\sum a_i\otimes X^i$. Routine calculations show that 
	$A\otimes K[X]\mapsto A[X]$, $\sum a_i\otimes X^i\mapsto \sum a_iX^i$, is a 
	linear algebra isomprhism. 
\end{proof}

\begin{exercise}
\label{xca:AM=MA}
	Prove that if $A$ is an algebra, then $A\otimes M_n(K)\simeq M_n(A)$. In
	particular, $M_n(K)\otimes M_m(K)\simeq M_{nm}(K)$.
\end{exercise}

Proposition \ref{pro:AKX=AX} and Exercise \ref{xca:AM=MA} 
are examples of a procedure known as \textbf{scalar extensions}. 

\begin{theorem}
	Let $A$ be an algebra over $K$ and $E$ be an extension of $K$ (this just simply means that
	$K$ is a subfield of $E$). Then 
	$A^E=E\otimes_KA$ is an algebra over $E$ with respect to
	the scalar multiplication 
	\[
		\lambda(\mu\otimes a)=(\lambda\mu)\otimes a,
	\]
	for all $\lambda,\mu\in E$ and $a\in A$.
\end{theorem}

\begin{proof}
	Let $\lambda\in E$. Since $E\times A\to E\otimes_KA$,
	$(\mu,a)\mapsto (\lambda\mu)\otimes a$, is $K$-bilinear, there exists 
	a linear map $E\otimes_KA\to E\otimes_KA$, $\mu\otimes a\mapsto
	(\lambda\mu)\otimes a$. The scalar multiplication is then well-defined and 
	\[
	\lambda(u+v)=\lambda u+\lambda v
	\]
	for all $\lambda\in E$ and $u,v\in E\otimes_KA$. Moreover, 
	\[
	(\lambda+\mu)u=\lambda u+\mu u,
	\quad
	(\lambda\mu)u=\lambda(\mu u),
	\quad
	\lambda(uv)=(\lambda u)v=u(\lambda v)
	\]
	for all $u,v\in E\otimes_KA$ and $\lambda,\mu\in E$.
\end{proof}

\begin{exercise}
    Prove the following statements:
    \begin{enumerate}
		\item $\{1\}\otimes A$ is a subalgebra of $A^E$ isomorphic to $A$.
		\item If $\{a_i:i\in I\}$ is a basis of $A$, then $\{1\otimes a_i:i\in
			I\}$ is a basis of $A^E$.
	\end{enumerate}
\end{exercise}

\begin{exercise}
	Prove that if $G$ is a group and $K$ is a subfield of $E$, then
	$E\otimes_K K[G]\simeq E[G]$.
\end{exercise}

Now we prove Formanek's theorem:

\begin{theorem}[Formanek]
	\index{Formanek's theorem}
	Let $K$ be a field of characteristic zero and let $G$ be a group. 
	If every element of $K[G]$ is invertible or a zero divisor, 
	then $G$ is locally finite. 
\end{theorem}

\begin{proof}
	Since $K$ is of characteristic zero, $\Q\subseteq K$. Then $K[G]\simeq
	K\otimes_{\Q}\Q[G]$. Each $\beta\in K\otimes_{\Q}\Q[Q]$ can be written
	uniquely as 
	\[
		\beta=1\otimes\beta_0+\sum k_i\otimes\beta_i,
	\]
	where $\{1,k_1,k_2,\dots,\}$ is a basis of $K$ as a $\Q$-vector space. 
	Let $\alpha\in\Q[G]$ and let $\beta\in K[G]$ be such that $\alpha\beta=1$. Since
	\[
	1\otimes 1=(1\otimes\alpha)\beta=1\otimes \alpha\beta_0+\sum k_i\otimes \alpha\beta_i,
	\]
	it follows that $\alpha\beta_0=1$. Similarly, if
	$\alpha\beta=0$, then $\alpha\beta_j=0$ for all $j$. Since 
	each $\alpha\in\Q[G]$ is invertible or a zero divisor, Formanek's theorems 
	for $\Q$ applies. 
\end{proof}

% \section*{Rickart's theorem}

% En esta sección vamos a demostrar que para cualquier grupo $G$ el radical de
% Jacobson de $\C[G]$ es cero. Demostraremos también que el radical de Jacobson
% de $\R[G]$ es cero.

% \begin{definition}
% 	\index{Anillo!con involución}
% 	\index{Involución!de un anillo}
% 	Sea $R$ un anillo. Una \textbf{involución} del anillo $R$ es un morfismo
% 	aditivo $R\to R$, $x\mapsto x^*$, tal que $x^{**}=x$ y $(xy)^*=y^*x^*$ para
% 	todo $x,y\in R$.
% \end{definition}

% De la definición se deduce inmediatamente que si $R$ es unitario, entonces
% $1^*=1$.

% \begin{example}
% 	La conjugación $z\mapsto\overline{z}$ es una involución de $\C$.
% \end{example}

% \begin{example}
% 	La trasposición $X\mapsto X^T$ es una involución del
% 	anillo $M_n(K)$.
% \end{example}

% \begin{example}
% 	Sea $G$ un grupo. Entonces
% 	$\left(\sum_{g\in G}\alpha_gg\right)^*=\sum_{g\in G}\overline{\alpha_g}g^{-1}$ 
% 	es una involución de $\C[G]$.
% \end{example}

% Dado un grupo $G$, se define la \textbf{traza} de un elemento
% $\alpha=\sum_{g\in G}\alpha_gg\in K[G]$ como $\trace(\alpha)=\alpha_1$. Es
% fácil ver que $\trace\colon K[G]\to K$, $\alpha\mapsto\trace(\alpha)$ es una
% función $K$-lineal tal que $\trace(\alpha\beta)=\trace(\beta\alpha)$.

% \begin{exercise}
% 	Sea $G$ un grupo finito y $K$ un cuerpo tal que su característica no divide al orden de $G$.
% 	Demuestre las siguientes afirmaciones:
% 	\begin{enumerate}
% 		\item Si $\alpha\in K[G]$ es nilpotente, entonces $\trace(\alpha)=0$.
% 		\item Si $\alpha\in K[G]$ es idempotente, entonces $\trace(\alpha)=\dim
% 			K[G]\alpha/|G|$.
% 	\end{enumerate}
% \end{exercise}

% \begin{exercise}
% 	Demuestre que 
% 	$\langle\alpha,\beta\rangle=\trace(\alpha\beta^*)$, $\alpha,\beta\in\C[G]$, 
% 	define un producto interno en $\C[G]$.
% \end{exercise}

% \begin{lemma}
% 	\label{lem:algebraico}
% 	Sea $G$ un grupo. Si $J(\C[G])\ne 0$, entonces existe $\alpha\in J(\C[G])$ tal que 
% 	$\trace(\alpha^{2^m})\in\R_{\geq1}$ 
% 	para todo $m\geq1$.
% \end{lemma}

% \begin{proof}
% 	Sea $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$. Entonces	
% 	\[
% 		\trace(\alpha^*\alpha)
% 		=\sum_{g\in G}\overline{\alpha_g}\alpha_g
% 		=\sum_{g\in G}|\alpha_g|^2\geq|\alpha_1|^2
% 		=|\trace(\alpha)|^2.
% 	\]
% 	Al usar esta fórmula para algún $\alpha$ tal que $\alpha^*=\alpha$ y usar
% 	inducción se obtiene que $\trace(\alpha^{2^m})\geq|\trace(\alpha)|^{2^m}$
% 	para todo $m\geq1$. 

% 	Sea $\beta=\sum_{g\in G}\beta_gg\in J(\C[G])$ tal que $\beta\ne0$. Como
% 	$\trace(\beta^*\beta)=\sum_{g\in G}|\beta_g|^2\ne0$ y $J(\C[G])$ es un ideal, 
% 	\[
% 		\alpha=\frac{\beta^*\beta}{\trace(\beta^*\beta)}\in J(\C[G]).
% 	\]
% 	Este elemento $\alpha$ cumple que $\alpha^*=\alpha$ y $\trace(\alpha)=1$.
% 	Luego $\trace(\alpha^{2^m})\geq 1$ para todo $m\geq1$.
% \end{proof}

% El ejercicio~\ref{exa:norma} implica que $\C[G]$ con
% $\dist(\alpha,\beta)=|\alpha-\beta|$ es un espacio métrico. En este espacio
% métrico, la función $\C[G]\to\C$, $\alpha\mapsto \trace(\alpha)$, es una
% función continua.

% \begin{lemma}
% 	\label{lem:phi_diferenciable}
% 	Sea $\alpha\in J(\C[G])$. La función
% 	\[
% 		\varphi\colon\C\to\C[G],\quad
% 		\varphi(z)=(1-z\alpha)^{-1},
% 	\]
% 	es continua, diferenciable y $\varphi(z)=\sum_{n\geq0}\alpha^nz^n\in\C[G]$ si $|z|$
% 	es suficientemente pequeño.
% \end{lemma}

% \begin{proof}	
% 	Sean $y,z\in\C$. Como $\varphi(y)$ y $\varphi(z)$ conmutan, 
% 	\begin{equation}
% 		\label{eq:Rickart}
% 		\begin{aligned}
% 			\varphi(y)-\varphi(z)&=\left( (1-z\alpha)-(1-y\alpha)\right)(1-y\alpha)^{-1}(1-z\alpha)^{-1}\\
% 			&=(y-z)\alpha\varphi(y)\varphi(z).
% 		\end{aligned}
% 	\end{equation}
% 	Entonces $|\varphi(y)|\leq|\varphi(z)|+|y-z||\alpha\varphi(y)||\varphi(z)|$ y luego
% 	\[
% 		|\varphi(y)|\left( 1-|y-z||\alpha\varphi(z)|\right)\leq|\varphi(z)|.
% 	\]
% 	Fijado $z$ podemos elegir $y$ suficientemente cerca de $z$ de forma tal que
% 	se cumpla que  $1-|y-z||\alpha\varphi(z)|\geq1/2$. Luego
% 	$|\varphi(y)|\leq2|\varphi(z)|$. De la igualdad~\eqref{eq:Rickart} se
% 	obtiene entonces $|\varphi(y)-\varphi(z)|\leq2|y-z||\alpha||\varphi(z)|^2$
% 	y luego $\varphi$ es una función continua. Por la
% 	expresión~\eqref{eq:Rickart}, 
% 	\[
% 	\varphi'(z)
% 	=\lim_{y\to z}\frac{\varphi(y)-\varphi(z)}{y-z}
% 	=\lim_{y\to z}\alpha\varphi(y)\varphi(z)
% 	=\alpha\varphi(z)^2
% 	\]
% 	para todo $z\in\C$.

% 	Si $z$ es tal que $|z||\alpha|=|z\alpha|<1$, entonces 
% 	\[
% 		\varphi(z)-\sum_{n=0}^Nz^n\alpha^n
% 		=\varphi(z)\left(1-(1-z\alpha)\sum_{n=0}^Nz^n\alpha^n\right)
% 		=\varphi(z)(z\alpha)^{N+1}
% 	\]
% 	y luego
% 	\[
% 		\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\leq|\varphi(z)||z\alpha|^{N+1}.
% 	\]
% 	Como $\varphi(z)$ está acotada cerca de $z=0$, se concluye que
% 	$\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\to0$ si $N\to\infty$.
% \end{proof}

% Estamos en condiciones de demostrar el teorema de Rickart:

% \begin{theorem}[Rickart]
% 	\index{Teorema!de Rickart}
% 	Si $G$ es un grupo, entonces $J(\C[G])=0$.
% \end{theorem}

% \begin{proof}
% 	Sea $\alpha\in J(\C[G])$ y sea $\varphi(z)=(1-\alpha z)^{-1}$. Sea 
% 	$f\colon\C\to \C$ dada por
% 	$f(z)=\trace\varphi(z)=\trace\left((1-z\alpha)^{-1}\right)$. Por el lema~\ref{lem:phi_diferenciable},
% 	$f(z)$ es una función entera tal que $f'(z)=\trace(\alpha\varphi(z)^2)$ y
% 	\begin{equation}
% 		\label{eq:Taylor}
% 		f(z)=\sum_{n=0}^\infty z^n\trace(\alpha^n)
% 	\end{equation}
% 	si $|z|$ es suficientemente pequeño. En particular, la
% 	igualdad~\eqref{eq:Taylor} es la expansión en serie de Taylor para $f(z)$
% 	en el origen. Esto implica que esta serie tiene radio de convergencia
% 	infinito y converge a $f(z)$ para todo $z\in\C$. En particular,
% 	\begin{equation}
% 		\label{eq:limite}
% 		\lim_{n\to\infty}\trace(\alpha^n)=0.
% 	\end{equation}
% 	Por otro lado, si $\alpha\ne0$ el lema~\ref{lem:algebraico} implica que
% 	$\trace(\alpha^{2^m})\geq1$ para todo $m\geq0$, lo que contradice el límite
% 	calculado en~\eqref{eq:limite}. Luego $\alpha=0$.
% \end{proof}

% Para demostrar un corolario necesitamos dos lemas:

% \begin{lemma}[Nakayama]
% 	\label{lem:Nakayama}
% 	\index{Lema!de Nakayama}
% 	Sea $R$ un anillo unitario y sea $M$ un $R$-módulo finitamente generado. Si
% 	$J(R)M=M$, entonces $M=0$.
% \end{lemma}

% \begin{proof}
% 	Supongamos que $M$ está generado por los elementos $x_1,\dots,x_n$. Como $x_n\in M=J(R)M$, 
% 	existen $r_1,\dots,r_n\in J(R)$ tales que $x_n=r_1x_1+\cdots+r_nx_n$, es decir
% 	$(1-r_n)x_n=\sum_{j=1}^{n-1}r_jx_j$. 
% 	Como $1-r_n$ es inversible, existe $s\in R$ tal que $s(1-r_n)=1$. Luego
% 	$x_n=\sum_{j=1}^{n-1}sr_jx_j$ 
% 	y entonces $M$ está generado por $x_1,\dots,x_{n-1}$. Al repetir este
% 	procedimiento una cierta cantidad finita de veces, se obtiene que $M=0$.
% \end{proof}

% \begin{lemma}
% 	\label{lem:Rickart}
% 	Sea $\iota\colon R\to S$ un morfismo de anillos unitarios. Si 
% 	\[
% 	S=\iota(R)x_1+\cdots+\iota(R)x_n,
% 	\]
% 	donde cada $x_j$ cumple que $x_jy=yx_j$ para todo $y\in\iota(R)$, entonces
% 	$\iota(J(R))\subseteq J(S)$.
% \end{lemma}

% \begin{proof}
% 	Veamos que $J=\iota(J(R))$ actúa trivialmente en cada $S$-módulo simple $M$.
% 	Si $M$ es un $S$-módulo simple, escribimos $M=Sm$ para algún $m\ne0$. Es
% 	claro que $M$ es un $R$-módulo con $r\cdot m=\iota(r)m$. Como
% 	\[
% 		M=Sm=(\iota(R)x_1+\cdots+\iota(R)x_n)m=\iota(R)(x_1m)+\cdots+\iota(R)(x_nm),
% 	\]
% 	$M$ es finitamente generado como $\iota(R)$-módulo. Además $J(R)\cdot
% 	M=JM=\iota(J)M$ es un $S$-submódulo de $M$ pues
% 	\[
% 		x_j(JM)=(x_jJ)M=(Jx_j)M=J(x_jM)\subseteq JM.
% 	\]
% 	Como $M\ne0$, el lema de Nakayama implica que $J(R)\cdot M\subsetneq M$. Luego,
% 	como $M$ es un $S$-módulo simple, se concluye que $J(R)M=0$.
% \end{proof}

% \begin{corollary}
% 	Si $G$ es un grupo, entonces $J(\R[G])=0$. 
% \end{corollary}

% \begin{proof}
% 	Sea $\iota\colon \R[G]\to\C[G]$ la inclusión canónica. Como 
% 	\[
% 	\C[G]=\R[G]+i\R[G],
% 	\]
% 	el lema~\ref{lem:Rickart} y el teorema de Rickart implican que
% 	$\iota(J(\R[G]))\subseteq J(\C[G])=0$. Luego $J(\R[G])=0$ pues $\iota$ es
% 	inyectiva. 
% \end{proof}


