\section{Lecture: Week 11}
\label{11}

\subsection{Formanek's theorem, I}

We start with some exercises. 

\begin{exercise}
\label{xca:invertible_algebraic}
	Let $K$ be a field. Let $A$ be a $K$-algebra algebraic over $K$ and $a\in A$.
	\begin{enumerate}
		\item $a$ is a left zero divisor if and only if $a$ is a right zero divisor.
		\item $a$ is left invertible if and only if $a$ is right invertible.
		\item $a$ is invertible if and only if $a$ is not a zero divisor.
	\end{enumerate}
\end{exercise}

\begin{exercise}
	\label{exa:norma}
	For $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$ let $|\alpha|=\sum_{g\in
	G}|\alpha_g|\in\R$. Prove the following statements:
	\begin{enumerate}
		%\item $|\trace(\alpha)|\leq |\alpha|$, 
		\item $|\alpha+\beta|\leq|\alpha|+|\beta|$, and 
		\item $|\alpha\beta|\leq|\alpha||\beta|$ 
	\end{enumerate}
	for all $\alpha,\beta\in\C[G]$.
\end{exercise}

\begin{theorem}[Formanek]
	\label{thm:FormanekQ}
	\index{Formanek's theorem}
	Let $G$ be a group. If every element of $\Q[G]$ is invertible or 
	a zero divisor, then $G$ is locally finite. 
\end{theorem}

\begin{proof}
	Let $\{x_1,\dots,x_n\}$ be a finite subset of $G$. Adding inverses if needed, we may assume that 
	$\{x_1,\dots,x_n\}$ generates the subgroup
	$H=\langle x_1,\dots,x_n\rangle$ as a semigroup. Let 
	\[
		\alpha=\frac{1}{2n}(x_1+\cdots+x_n)\in\Q[G]
	\]
    Note that $|\alpha|\leq 1/2$. 
	We claim that $1-\alpha\in\Q[G]$ is invertible. If not, then it is a zero divisor. If there exists 
	$\delta\in\Q[G]$ such that $\delta(1-\alpha)=0$, then 
	$\delta=\delta\alpha$. Since  
	\[
		|\delta|=|\delta\alpha|\leq|\delta||\alpha|\leq|\delta|/2,
	\]
	it follows that $\delta=0$. Similarly, $(1-\alpha)\delta=0$ implies
	$\delta=0$. 
	
	Let $\beta=(1-\alpha)^{-1}\in\Q[G]$.  For each $k$ let  
	\[
		\gamma_k=(1+\alpha+\cdots+\alpha^k)-\beta.
	\]
	Then 
	\begin{align*}
		\gamma_k(1-\alpha)&=(1+\alpha+\cdots+\alpha^k-\beta)(1-\alpha)\\
		&=(1+\alpha+\cdots+\alpha^k)(1-\alpha)-\beta(1-\alpha)=-\alpha^{k+1}
	\end{align*}
	and thus  
	$\gamma_k=-\alpha^{k+1}\beta$. Since  
	\[
		|\gamma_k|=|-\alpha^{k+1}\beta|\leq|\beta||\alpha^{k+1}|\leq\frac{|\beta|}{2^{k+1}},
	\]
	it follows that $\lim_{k\to\infty}|\gamma_k|=0$. 

	We now prove that $H\subseteq\supp\beta$. This will finish the proof of the theorem, 
	as $\supp\beta$ is a finite subset of $G$ by definition. If
	$H\not\subseteq\supp\beta$, let $h\in H\setminus\supp\beta$.  Assume that 
    $h=x_{i_1}\cdots x_{i_m}$ is a word in the letters $x_j$ of length $m$. Let 
    $c_j$ be the coefficient of $h$ in $\alpha^j$. Then $c_0+\cdots+c_k$ is the 
	coefficient of $h$ in $\gamma_k$, but 
	\[
		|\gamma_k|\geq c_0+c_1+\cdots+c_k\geq c_m>0
	\]
	for all $k\geq m$, as each $c_j$ is non-negative, a contradiction to 
	$|\gamma_k|\to 0$ if $k\to\infty$.
\end{proof}



\subsection{Tensor products}

The \emph{tensor product} of the vector spaces (over $K$) $U$ and $V$ 
is the quotient vector space $K[U\times V]/T$, where $K[U\times V]$ 
is the vector space with basis 
\[
\{(u,v):u\in U,v\in V\}
\]
and $T$ is the subspace 
generated by elements of the form 
\[
		(\lambda u+\mu u',v)-\lambda(u,v)-\mu(u',v),\quad
		(u,\lambda v+\mu v')-\lambda(u,v)-\mu(u,v')
	\]
for $\lambda,\mu\in K$, $u,u'\in U$ and $v,v'\in V$.
The tensor product of $U$ and $V$ will be denoted by $U\otimes_KV$ or 
$U\otimes V$ when the base field is clear from the context. For $u\in U$ and 
$v\in V$ we write $u\otimes v$ to denote the coset $(u,v)+T$.

\begin{theorem}
	Let $U$ and $V$ be vector spaces. Then there exists a bilinear map 
	\[
    U\times V\to U\otimes V,\quad (u,v)\mapsto u\otimes v,
    \]
    such that 
	each element of $U\otimes V$ is a finite sum of the form 
	\[
		\sum_{i=1}^N u_i\otimes v_i
	\]
	for some $u_1,\dots,u_N\in U$ and $v_1,\dots,v_N\in V$. 
	Moreover, if $W$ is a vector space and 
 \[
 \beta\colon U\times V\to W
 \]
 is a bilinear map, 
	there exists a linear map 
	$\overline{\beta}\colon U\otimes V\to W$ such that $\overline{\beta}(u\otimes
	v)=\beta(u,v)$ for all $u\in U$ and $v\in V$.
\end{theorem}

\begin{proof}
    By definition, the map
    \[
	U\times V\to U\otimes V,\quad
	(u,v)\mapsto u\otimes v,
	\]
	is bilinear. From the definitions, it follows that
	$U\otimes V$ is a finite linear combination of elements of the form 
	$u\otimes v$, where $u\in U$ and $v\in V$. Since $\lambda(u\otimes
	v)=(\lambda u)\otimes v$ for all $\lambda\in K$, the first claim follows.

	Since the elements of $U\times V$ form a basis of $K[U\times V]$, there exists
	a linear map 
	\[
		\gamma\colon K[U\times V]\to W,\quad
	\gamma(u,v)=\beta(u,v). 
	\]
	Since $\beta$ is bilinear by assumption, $T\subseteq\ker\gamma$. It follows that there exists 
	a linear map $\overline{\beta}\colon U\otimes V\to
	W$ such that  
	\[
	\begin{tikzcd}
		K[U\times V] \arrow[r]\arrow[d] & W \\
		U\otimes V\arrow[ur, dashrightarrow]
	\end{tikzcd}
	\]
	commutes. In particular, $\overline{\beta}(u\otimes v)=\beta(u,v)$. 
\end{proof}

\begin{exercise}
	\label{xca:tensorial_unicidad}
	Prove that the properties of the previous theorem characterize tensor products up to isomorphism. 
\end{exercise}

Some properties:
%Observemos
%que todo elemento de $U\otimes V$ es una suma finita
%de la forma 
%\[
%	\sum_{i=1}^N u_i\otimes v_i
%\]
%para $N\in\N$, $u_i\in U$ y $v_i\in V$. Esta expresión no es única. Vale además
%que $u\otimes 0=0=0\otimes v$ para todo $u\in U$ y $v\in V$.

\begin{proposition}
	Let $\varphi\colon U\to U_1$ and $\psi\colon V\to V_1$ be linear maps. There
	exists a unique linear map 
	$\varphi\otimes\psi\colon U\otimes V\to U_1\otimes V_1$ such that
	\[
		(\varphi\otimes\psi)(u\otimes v)=\varphi(u)\otimes\psi(v)
	\]
	for all $u\in U$ and $v\in V$.
\end{proposition}

\begin{proof}
	Since $U\times V\to U_1\otimes V_1$,
	$(u,v)\mapsto\varphi(u)\otimes\psi(v)$, is bilinear, there exists a linear map
	$U\otimes V\to U_1\otimes V_1$, $u\otimes
	v\to\varphi(u)\otimes\psi(v)$. Thus 
	\[
		\sum u_i\otimes v_i\mapsto\sum\varphi(u_i)\otimes\psi(v_i)
	\]
	is well-defined. 
\end{proof}

\begin{exercise}
    Prove the following statements:
	\begin{enumerate}
		\item $(\varphi\otimes\psi)(\varphi'\otimes\psi')=(\varphi\varphi')\otimes(\psi\psi')$.
		\item If $\varphi$ and $\psi$ are isomorphisms, then 
			$\varphi\otimes\psi$ is an isomorphism. 
		\item $(\lambda\varphi+\lambda'\varphi')\otimes\psi=\lambda\varphi\otimes\psi+\lambda'\varphi'\otimes\psi$.
		\item $\varphi\otimes(\lambda\psi+\lambda'\psi')=\lambda\varphi\otimes\psi+\lambda'\varphi\otimes\psi'$.
		\item If $U\simeq U_1$ and $V\simeq V_1$, then $U\otimes V\simeq U_1\otimes V_1$.
	\end{enumerate}
\end{exercise}

The following proposition is extremely useful:

\begin{proposition}
	If $U$ and $V$ are vector spaces, then  
	$U\otimes V\simeq V\otimes U$.
\end{proposition}

\begin{proof}
	Since $U\times V\to V\otimes U$, $(u,v)\mapsto v\otimes u$, is bilinear, there exists 
	a linear map 
    \[
    U\otimes V\to V\otimes U,\quad u\otimes
	v\mapsto v\otimes u.
    \]
    Similarly, there exists a linear map 
	\[
    V\otimes U\to U\otimes V,\quad  v\otimes u\mapsto
	u\otimes v.
    \]
    Thus $U\otimes V\simeq V\otimes U$.
\end{proof}

\begin{exercise}
	\label{xca:UxVxW}
    Prove that $(U\otimes V)\otimes W\simeq U\otimes(V\otimes W)$.
\end{exercise}

\begin{exercise}
	\label{xca:UxK}
	Prove that $U\otimes K\simeq U\simeq K\otimes U$.
\end{exercise}

\begin{proposition}
	\label{pro:U_LI}
	Let $U$ and $V$ be vector spaces. 
	If $\{u_1,\dots,u_n\}$ is a linearly independent subset of $U$ and 
	$v_1,\dots,v_n\in V$ is such that $\sum_{i=1}^n u_i\otimes v_i=0$, then 
    $v_i=0$ for all $i\in\{1,\dots,n\}$.
\end{proposition}

\begin{proof}
	Let $i\in\{1,\dots,n\}$ and 
	\[
	f_i\colon U\to K,
	\quad
	f_i(u_j)=\delta_{ij}=\begin{cases}
	1 & \text{if $i=j$},\\
	0 & \text{otherwise}.
	\end{cases}
	\]
	Since the map 
 \[
 U\times V\to V,\quad (u,v)\mapsto f_i(u)v,
 \]
 is bilinear, there exists 
	a linear map 
	$\alpha_i\colon U\otimes V\to V$ such that $\alpha_i(u\otimes
	v)=f_i(u)v$. Thus
	\[
		v_i=\sum_{j=1}^n\alpha_i(u_j\otimes v_j)=\alpha_i\left(\sum_{j=1}^nu_j\otimes v_j\right)=0.\qedhere
	\]
\end{proof}

\begin{exercise}
	\label{xca:uxv=0}
	Prove that $u\otimes v=0$ and $v\ne 0$ imply $u=0$.
\end{exercise}

\begin{theorem}
    Let $U$ and $V$ be vector spaces. 
	If $\{u_i:i\in I\}$ is a basis of $U$ and $\{v_j:j\in J\}$ is a basis of $V$, then 
	$\{u_i\otimes v_j:i\in I,j\in J\}$ is a basis of $U\otimes
	V$.
\end{theorem}

\begin{proof}
	The $u_i\otimes v_j$ are generators of $U\otimes V$, as  
    $u=\sum_i\lambda_iu_i$ and $v=\sum_j\mu_jv_j$ imply 
	\[
    u\otimes v=\sum_{i,j}\lambda_i\mu_ju_i\otimes v_j.
    \]
	We now prove that the $u_i\otimes v_j$ are linearly independent. We need to show that
	each finite subset of the $u_i\otimes v_j$
	is linearly independent. If $\sum_k\sum_l\lambda_{kl}u_{i_k}\otimes
	v_{j_l}=0$, then 
	\[
0=\sum_{k}u_{i_k}\otimes\left(\sum_{l}\lambda_{kl}v_{j_l}\right).\]
    Since  
	the $u_{i_k}$ are linearly independent, Proposition~\ref{pro:U_LI}
	implies that $\sum_{l}\lambda_{kl}v_{j_l}=0$. Thus $\lambda_{kl}=0$ for all 
	$k,l$, as the $v_{j_l}$ are linearly independent. 
\end{proof}

If $U$ and $V$ are finite-dimensional vector spaces, then 
\[
	\dim(U\otimes V)=(\dim U)(\dim V).
\]

\begin{corollary}
	If $\{u_i:i\in I\}$ is a basis of $U$, then every element of $U\otimes V$
	can be written uniquely as a finite sum $\sum_{i}u_i\otimes v_i$.
\end{corollary}

\begin{proof}
	Every element of the tensor product $U\otimes V$ is a finite sum 
	of the form $\sum_i x_i\otimes y_i$, where $x_i\in U$ and $y_i\in V$. If  
	$x_i=\sum_j\lambda_{ij}u_j$, then 
	\[
		\sum_i x_i\otimes y_i=\sum_i\left(\sum_j\lambda_{ij}u_j\right)\otimes y_i		
		=\sum_j u_j\otimes\left(\sum_i\lambda_{ij}y_i\right).\qedhere 
	\]
\end{proof}

%\begin{corollary}
%	Todo elemento no nulo de $U\otimes V$ puede escribirse como una suma finita
%	$\sum_{i=1}^N u_i\otimes v_i$ para un conjuntos $\{u_i:1\leq i\leq
%	N\}\subseteq U$ y $\{v_i:1\leq i\leq N\}\subseteq V$ linealmente
%	independientes.
%\end{corollary}
%
%\begin{proof}
%	tomar $N$ minimal	
%\end{proof}

\begin{exercise}
\label{xca:tensor_algebras}
    Let $A$ and $B$ be algebras. Prove that $A\otimes B$ 
    is an algebra with 
	\[
		(a\otimes b)(x\otimes y)=ax\otimes by.
	\]
\end{exercise}

% \begin{proof}
% 	Para $x\in A$, $y\in B$ consideramos $R_x\otimes R_y\in\End_K(A\otimes B)$.
% 	Como la función $A\times B\to\End_K(A\otimes B)$, $(x,y)\mapsto R_x\otimes
% 	R_y$, es bilineal, existe una función lineal $\varphi\colon A\otimes
% 	B\to\End_K(A\otimes B)$, $\varphi(x\otimes y)=R_x\otimes R_y$. Para $u,v\in A\otimes B$ definimos
% 	\[
% 		uv=\varphi(v)(u).
% 	\]
% 	Esta operación es bilineal pues por ejemplo
% 	\[
% 		u(v+w)=\varphi(v+w)(u)=(\varphi(v)+\varphi(w))(u)=\varphi(v)(u)+\varphi(w)(u)=uv+uw.
% 	\]
% 	Además
% 	$(a\otimes b)(x\otimes y)=\varphi(x\otimes y)(a\otimes b)=(R_x\otimes R_y)(a\otimes b)=ax\otimes by$.
% 	Un cálculo sencillo muestra que este producto es asociativo.
% \end{proof}

\begin{exercise}
    Let $K$ be a field and $A,B,C$ be $K$-algebras. 
    Prove the following statements:
	\begin{enumerate}
		\item $A\otimes B\simeq B\otimes A$.
		\item $(A\otimes B)\otimes C\simeq A\otimes(B\otimes C)$.
		\item $A\otimes K\simeq A\simeq K\otimes A$.
		\item If $A\simeq A_1$ and $B\simeq B_1$, then $A\otimes B\simeq A_1\otimes B_1$.
	\end{enumerate}
\end{exercise}

Some examples:

\begin{proposition}
	If $G$ and $H$ are groups, then $K[G]\otimes K[H]\simeq K[G\times H]$.
\end{proposition}

\begin{proof}
	The set $\{g\otimes h:g\in G,h\in H\}$ is a basis of $K[G]\otimes K[H]$ and 
	the elements of $G\times H$ form a basis of $K[G\times H]$. There exists a linear isomorphism 
	\[
	K[G]\otimes K[H]\to K[G\times H], 
	\quad 
	g\otimes h\mapsto (g,h),
	\]
	that is multiplicative. Thus $K[G]\otimes K[H]\simeq K[G\times H]$
	as algebras. 
\end{proof}

\begin{proposition}
\label{pro:AKX=AX}
	If $A$ is an algebra, then $A\otimes K[X]\simeq A[X]$.	
\end{proposition}

\begin{proof}
	Each element of the tensor product $A\otimes K[X]$ can be written uniquely as a finite sum of
	the form $\sum a_i\otimes X^i$. Routine calculations show that 
	$A\otimes K[X]\mapsto A[X]$, $\sum a_i\otimes X^i\mapsto \sum a_iX^i$, is a 
	linear algebra isomorphism. 
\end{proof}

\begin{exercise}
\label{xca:AM=MA}
	Prove that if $A$ is an algebra, then $A\otimes M_n(K)\simeq M_n(A)$. In
	particular, $M_n(K)\otimes M_m(K)\simeq M_{nm}(K)$.
\end{exercise}

Proposition \ref{pro:AKX=AX} and Exercise \ref{xca:AM=MA} 
are examples of a procedure known as \emph{scalar extensions}. 

\begin{theorem}
\label{thm:extensions_scalars}
	Let $A$ be an algebra over $K$ and $E$ be an extension of $K$ (this just simply means that
	$K$ is a subfield of $E$). Then 
	$A^E=E\otimes_KA$ is an algebra over $E$ with respect to
	the scalar multiplication 
	\[
		\lambda(\mu\otimes a)=(\lambda\mu)\otimes a,
	\]
	for all $\lambda,\mu\in E$ and $a\in A$.
\end{theorem}

\begin{proof}
	Let $\lambda\in E$. Since $E\times A\to E\otimes_KA$,
	$(\mu,a)\mapsto (\lambda\mu)\otimes a$, is $K$-bilinear, there exists 
	a linear map $E\otimes_KA\to E\otimes_KA$, $\mu\otimes a\mapsto
	(\lambda\mu)\otimes a$. The scalar multiplication is then well-defined and 
	\[
	\lambda(u+v)=\lambda u+\lambda v
	\]
	for all $\lambda\in E$ and $u,v\in E\otimes_KA$. Moreover, 
	\[
	(\lambda+\mu)u=\lambda u+\mu u,
	\quad
	(\lambda\mu)u=\lambda(\mu u),
	\quad
	\lambda(uv)=(\lambda u)v=u(\lambda v)
	\]
	for all $u,v\in E\otimes_KA$ and $\lambda,\mu\in E$.
\end{proof}

\begin{exercise}
    Prove the following statements:
    \begin{enumerate}
		\item $\{1\}\otimes A$ is a subalgebra of $A^E$ isomorphic to $A$.
		\item If $\{a_i:i\in I\}$ is a basis of $A$, then $\{1\otimes a_i:i\in
			I\}$ is a basis of $A^E$.
	\end{enumerate}
\end{exercise}

\begin{exercise}
	Prove that if $G$ is a group and $K$ is a subfield of $E$, then
	\[
	E\otimes_K K[G]\simeq E[G].
	\]
\end{exercise}

\subsection{Formanek's theorem, II}

The combination of technique known as extensions of scalars we have seen in the previous section
and Formanek's theorem for rational group algebras 
yield the following general result. 

\begin{theorem}[Formanek]
	\index{Formanek's theorem}
	Let $K$ be a field of characteristic zero and let $G$ be a group. 
	If every element of $K[G]$ is invertible or a zero divisor, 
	then $G$ is locally finite. 
\end{theorem}

\begin{proof}
	Since $K$ is of characteristic zero, $\Q\subseteq K$. Then $K[G]\simeq
	K\otimes_{\Q}\Q[G]$. Note that each $\beta\in K\otimes_{\Q}\Q[Q]$ can be written
	uniquely as 
	\[
		\beta=1\otimes\beta_0+\sum k_i\otimes\beta_i,
	\]
	where $\{1,k_1,k_2,\dots,\}$ is a basis of $K$ as a $\Q$-vector space. 
	Let $\alpha\in\Q[G]\subseteq K[G]$. By assumption, every element of $K[G]$ is 
    invertible or a zero divisor. Assume first that $\alpha$ is invertible. 
    Let $\beta\in K[G]\simeq K\otimes_{\Q}\Q[Q]$ be such that $\alpha\beta=1$. Since
	\[
	1\otimes 1=(1\otimes\alpha)\beta=1\otimes \alpha\beta_0+\sum k_i\otimes \alpha\beta_i,
	\]
	it follows that $\alpha\beta_0=1$. Thus $\alpha$ is invertible in $\Q[G]$. Similarly, if
    $\alpha$ is a zero divisor, then 
	$\alpha\beta=0$ and $\alpha\beta_j=0$ for all $j$. Thus $\alpha$ is a zero divisor in $\Q[G]$. 
    Hence 
	each $\alpha\in\Q[G]$ is invertible or a zero divisor, so Formanek's theorem 
	for $\Q$ applies.
\end{proof}

% \section*{Rickart's theorem}

% En esta sección vamos a demostrar que para cualquier grupo $G$ el radical de
% Jacobson de $\C[G]$ es cero. Demostraremos también que el radical de Jacobson
% de $\R[G]$ es cero.

% \begin{definition}
% 	\index{Anillo!con involución}
% 	\index{Involución!de un anillo}
% 	Sea $R$ un anillo. Una \emph{involución} del anillo $R$ es un morfismo
% 	aditivo $R\to R$, $x\mapsto x^*$, tal que $x^{**}=x$ y $(xy)^*=y^*x^*$ para
% 	todo $x,y\in R$.
% \end{definition}

% De la definición se deduce inmediatamente que si $R$ es unitario, entonces
% $1^*=1$.

% \begin{example}
% 	La conjugación $z\mapsto\overline{z}$ es una involución de $\C$.
% \end{example}

% \begin{example}
% 	La trasposición $X\mapsto X^T$ es una involución del
% 	anillo $M_n(K)$.
% \end{example}

% \begin{example}
% 	Sea $G$ un grupo. Entonces
% 	$\left(\sum_{g\in G}\alpha_gg\right)^*=\sum_{g\in G}\overline{\alpha_g}g^{-1}$ 
% 	es una involución de $\C[G]$.
% \end{example}

% Dado un grupo $G$, se define la \emph{traza} de un elemento
% $\alpha=\sum_{g\in G}\alpha_gg\in K[G]$ como $\trace(\alpha)=\alpha_1$. Es
% fácil ver que $\trace\colon K[G]\to K$, $\alpha\mapsto\trace(\alpha)$ es una
% función $K$-lineal tal que $\trace(\alpha\beta)=\trace(\beta\alpha)$.

% \begin{exercise}
% 	Sea $G$ un grupo finito y $K$ un cuerpo tal que su característica no divide al orden de $G$.
% 	Demuestre las siguientes afirmaciones:
% 	\begin{enumerate}
% 		\item Si $\alpha\in K[G]$ es nilpotente, entonces $\trace(\alpha)=0$.
% 		\item Si $\alpha\in K[G]$ es idempotente, entonces $\trace(\alpha)=\dim
% 			K[G]\alpha/|G|$.
% 	\end{enumerate}
% \end{exercise}

% \begin{exercise}
% 	Demuestre que 
% 	$\langle\alpha,\beta\rangle=\trace(\alpha\beta^*)$, $\alpha,\beta\in\C[G]$, 
% 	define un producto interno en $\C[G]$.
% \end{exercise}

% \begin{lemma}
% 	\label{lem:algebraico}
% 	Sea $G$ un grupo. Si $J(\C[G])\ne 0$, entonces existe $\alpha\in J(\C[G])$ tal que 
% 	$\trace(\alpha^{2^m})\in\R_{\geq1}$ 
% 	para todo $m\geq1$.
% \end{lemma}

% \begin{proof}
% 	Sea $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$. Entonces	
% 	\[
% 		\trace(\alpha^*\alpha)
% 		=\sum_{g\in G}\overline{\alpha_g}\alpha_g
% 		=\sum_{g\in G}|\alpha_g|^2\geq|\alpha_1|^2
% 		=|\trace(\alpha)|^2.
% 	\]
% 	Al usar esta fórmula para algún $\alpha$ tal que $\alpha^*=\alpha$ y usar
% 	inducción se obtiene que $\trace(\alpha^{2^m})\geq|\trace(\alpha)|^{2^m}$
% 	para todo $m\geq1$. 

% 	Sea $\beta=\sum_{g\in G}\beta_gg\in J(\C[G])$ tal que $\beta\ne0$. Como
% 	$\trace(\beta^*\beta)=\sum_{g\in G}|\beta_g|^2\ne0$ y $J(\C[G])$ es un ideal, 
% 	\[
% 		\alpha=\frac{\beta^*\beta}{\trace(\beta^*\beta)}\in J(\C[G]).
% 	\]
% 	Este elemento $\alpha$ cumple que $\alpha^*=\alpha$ y $\trace(\alpha)=1$.
% 	Luego $\trace(\alpha^{2^m})\geq 1$ para todo $m\geq1$.
% \end{proof}

% El ejercicio~\ref{exa:norma} implica que $\C[G]$ con
% $\dist(\alpha,\beta)=|\alpha-\beta|$ es un espacio métrico. En este espacio
% métrico, la función $\C[G]\to\C$, $\alpha\mapsto \trace(\alpha)$, es una
% función continua.

% \begin{lemma}
% 	\label{lem:phi_diferenciable}
% 	Sea $\alpha\in J(\C[G])$. La función
% 	\[
% 		\varphi\colon\C\to\C[G],\quad
% 		\varphi(z)=(1-z\alpha)^{-1},
% 	\]
% 	es continua, diferenciable y $\varphi(z)=\sum_{n\geq0}\alpha^nz^n\in\C[G]$ si $|z|$
% 	es suficientemente pequeño.
% \end{lemma}

% \begin{proof}	
% 	Sean $y,z\in\C$. Como $\varphi(y)$ y $\varphi(z)$ conmutan, 
% 	\begin{equation}
% 		\label{eq:Rickart}
% 		\begin{aligned}
% 			\varphi(y)-\varphi(z)&=\left( (1-z\alpha)-(1-y\alpha)\right)(1-y\alpha)^{-1}(1-z\alpha)^{-1}\\
% 			&=(y-z)\alpha\varphi(y)\varphi(z).
% 		\end{aligned}
% 	\end{equation}
% 	Entonces $|\varphi(y)|\leq|\varphi(z)|+|y-z||\alpha\varphi(y)||\varphi(z)|$ y luego
% 	\[
% 		|\varphi(y)|\left( 1-|y-z||\alpha\varphi(z)|\right)\leq|\varphi(z)|.
% 	\]
% 	Fijado $z$ podemos elegir $y$ suficientemente cerca de $z$ de forma tal que
% 	se cumpla que  $1-|y-z||\alpha\varphi(z)|\geq1/2$. Luego
% 	$|\varphi(y)|\leq2|\varphi(z)|$. De la igualdad~\eqref{eq:Rickart} se
% 	obtiene entonces $|\varphi(y)-\varphi(z)|\leq2|y-z||\alpha||\varphi(z)|^2$
% 	y luego $\varphi$ es una función continua. Por la
% 	expresión~\eqref{eq:Rickart}, 
% 	\[
% 	\varphi'(z)
% 	=\lim_{y\to z}\frac{\varphi(y)-\varphi(z)}{y-z}
% 	=\lim_{y\to z}\alpha\varphi(y)\varphi(z)
% 	=\alpha\varphi(z)^2
% 	\]
% 	para todo $z\in\C$.

% 	Si $z$ es tal que $|z||\alpha|=|z\alpha|<1$, entonces 
% 	\[
% 		\varphi(z)-\sum_{n=0}^Nz^n\alpha^n
% 		=\varphi(z)\left(1-(1-z\alpha)\sum_{n=0}^Nz^n\alpha^n\right)
% 		=\varphi(z)(z\alpha)^{N+1}
% 	\]
% 	y luego
% 	\[
% 		\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\leq|\varphi(z)||z\alpha|^{N+1}.
% 	\]
% 	Como $\varphi(z)$ está acotada cerca de $z=0$, se concluye que
% 	$\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\to0$ si $N\to\infty$.
% \end{proof}

% Estamos en condiciones de demostrar el teorema de Rickart:

% \begin{theorem}[Rickart]
% 	\index{Teorema!de Rickart}
% 	Si $G$ es un grupo, entonces $J(\C[G])=0$.
% \end{theorem}

% \begin{proof}
% 	Sea $\alpha\in J(\C[G])$ y sea $\varphi(z)=(1-\alpha z)^{-1}$. Sea 
% 	$f\colon\C\to \C$ dada por
% 	$f(z)=\trace\varphi(z)=\trace\left((1-z\alpha)^{-1}\right)$. Por el lema~\ref{lem:phi_diferenciable},
% 	$f(z)$ es una función entera tal que $f'(z)=\trace(\alpha\varphi(z)^2)$ y
% 	\begin{equation}
% 		\label{eq:Taylor}
% 		f(z)=\sum_{n=0}^\infty z^n\trace(\alpha^n)
% 	\end{equation}
% 	si $|z|$ es suficientemente pequeño. En particular, la
% 	igualdad~\eqref{eq:Taylor} es la expansión en serie de Taylor para $f(z)$
% 	en el origen. Esto implica que esta serie tiene radio de convergencia
% 	infinito y converge a $f(z)$ para todo $z\in\C$. En particular,
% 	\begin{equation}
% 		\label{eq:limite}
% 		\lim_{n\to\infty}\trace(\alpha^n)=0.
% 	\end{equation}
% 	Por otro lado, si $\alpha\ne0$ el lema~\ref{lem:algebraico} implica que
% 	$\trace(\alpha^{2^m})\geq1$ para todo $m\geq0$, lo que contradice el límite
% 	calculado en~\eqref{eq:limite}. Luego $\alpha=0$.
% \end{proof}

% Para demostrar un corolario necesitamos dos lemas:

% \begin{lemma}[Nakayama]
% 	\label{lem:Nakayama}
% 	\index{Lema!de Nakayama}
% 	Sea $R$ un anillo unitario y sea $M$ un $R$-módulo finitamente generado. Si
% 	$J(R)M=M$, entonces $M=0$.
% \end{lemma}

% \begin{proof}
% 	Supongamos que $M$ está generado por los elementos $x_1,\dots,x_n$. Como $x_n\in M=J(R)M$, 
% 	existen $r_1,\dots,r_n\in J(R)$ tales que $x_n=r_1x_1+\cdots+r_nx_n$, es decir
% 	$(1-r_n)x_n=\sum_{j=1}^{n-1}r_jx_j$. 
% 	Como $1-r_n$ es inversible, existe $s\in R$ tal que $s(1-r_n)=1$. Luego
% 	$x_n=\sum_{j=1}^{n-1}sr_jx_j$ 
% 	y entonces $M$ está generado por $x_1,\dots,x_{n-1}$. Al repetir este
% 	procedimiento una cierta cantidad finita de veces, se obtiene que $M=0$.
% \end{proof}

% \begin{lemma}
% 	\label{lem:Rickart}
% 	Sea $\iota\colon R\to S$ un morfismo de anillos unitarios. Si 
% 	\[
% 	S=\iota(R)x_1+\cdots+\iota(R)x_n,
% 	\]
% 	donde cada $x_j$ cumple que $x_jy=yx_j$ para todo $y\in\iota(R)$, entonces
% 	$\iota(J(R))\subseteq J(S)$.
% \end{lemma}

% \begin{proof}
% 	Veamos que $J=\iota(J(R))$ actúa trivialmente en cada $S$-módulo simple $M$.
% 	Si $M$ es un $S$-módulo simple, escribimos $M=Sm$ para algún $m\ne0$. Es
% 	claro que $M$ es un $R$-módulo con $r\cdot m=\iota(r)m$. Como
% 	\[
% 		M=Sm=(\iota(R)x_1+\cdots+\iota(R)x_n)m=\iota(R)(x_1m)+\cdots+\iota(R)(x_nm),
% 	\]
% 	$M$ es finitamente generado como $\iota(R)$-módulo. Además $J(R)\cdot
% 	M=JM=\iota(J)M$ es un $S$-submódulo de $M$ pues
% 	\[
% 		x_j(JM)=(x_jJ)M=(Jx_j)M=J(x_jM)\subseteq JM.
% 	\]
% 	Como $M\ne0$, el lema de Nakayama implica que $J(R)\cdot M\subsetneq M$. Luego,
% 	como $M$ es un $S$-módulo simple, se concluye que $J(R)M=0$.
% \end{proof}

% \begin{corollary}
% 	Si $G$ es un grupo, entonces $J(\R[G])=0$. 
% \end{corollary}

% \begin{proof}
% 	Sea $\iota\colon \R[G]\to\C[G]$ la inclusión canónica. Como 
% 	\[
% 	\C[G]=\R[G]+i\R[G],
% 	\]
% 	el lema~\ref{lem:Rickart} y el teorema de Rickart implican que
% 	$\iota(J(\R[G]))\subseteq J(\C[G])=0$. Luego $J(\R[G])=0$ pues $\iota$ es
% 	inyectiva. 
% \end{proof}




